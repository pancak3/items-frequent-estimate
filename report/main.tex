\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, left=25mm, top=25mm, right=25mm, bottom=25mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{minted}
\usepackage[english]{babel,isodate}
\usepackage[pdftex, pdfauthor={Qifan Deng},
 pdftitle={COMP90056 - Stream Computing and Applications 2020, Assignment 2}, 
 pdfsubject={COMP90056 Assignment}]{hyperref}
\usepackage{pgfplots} 
\usepackage{SIunits}        % <-- required in preamble
\pgfplotsset{compat=newest} % 
\usepackage[justification=centering]{caption}
\usepackage{minted}
\usepackage{enumitem}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{epstopdf}

\newcommand\gauss[2]{1/(#2*sqrt(2*pi))*exp(-((x-#1)^2)/(2*#2^2))}
\newcommand{\Mod}[1]{\ (\mathrm{mod}\ #1)}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

\setlength{\columnsep}{20pt}
\setlength{\parindent}{8pt}
\setlength{\parskip}{3pt}

\pgfplotsset{compat=1.16}

\title{COMP90056 - Stream Computing and Applications 2020, Assignment 2 
\\Frequent Items in a Data Stream}
\author{
  Qifan Deng (1077479)\\
  \texttt{qifand@student.unimelb.edu.au} }
\date{\printdayoff\normalsize\today}

\begin{document}
\sloppy
% \twocolumn
\maketitle

\section{Introduction}
Three algorithms are implemented in this report to estimate the most frequent items of a data stream.
They are StickySampling, LossyCounting and SpaceSaving. 
There is also a Baseline algorithm implemented to investigate the performance of the three algorithms.
Results of experiments are provided in Section? which show ? 

\section{Hardware \& Environments \& Data Stream}

\paragraph{Hardware}
The experiments in section are conducted on a machin with the following specs
\begin{itemize}
     \setlength\itemsep{1pt}
       \item CPU: 1.8 GHz Quad-Core Intel Core i5
       \item Memory: 8 GB 2133 MHz LPDDR3
       \item Disk: WDC PC SN720 SDAPNTW-512G-1127 SSD
\end{itemize}
\paragraph{Environment}
The testing operating system is macOS Catalina version 10.15.7 (19H2).
All the algorithms are implemented in Python 3.8.5.
The requirements of the algorithms are stored in requirements.txt which can be installed with command pip install -r requirements.txt.

\paragraph{Repeat Tests}
Once the environments are prepared, run python3 main.py to get all the figures in this report.

\paragraph{Data Stream}
The data stream is power-law distribution where 
the $i^{th}$ most frequent item has probability $\frac{1}{i^{z} \cdot{} Zeta(z)}$
where $z$ is a positive real-value parameter and $Zeta$ is Riemann or Hurwitz zeta function ?. 
Figure~\ref{powerlaw} shows the distribution when $z = \{1.1, 1.4, 1.7, 2.0\}$ and the data stream size is $10^6$.
As it shows, they have almost the ideal trend except when $z$ is close to 1. 
This proves that data streams in this report are desired.
Besides, as Figure~\ref{powerlaw} annotates, there are $717130$ items has frequency at least 1\% when $z=1.1$,  
$819018$ when  $z=1.4$, $880423$ when $z=1.7$ and $924202$ when $z=2.0$.


\begin{figure}[!t]
     \begin{subfigure}[b]{0.5\textwidth}
          \centering
          \resizebox{\linewidth}{!}{\includegraphics{eps/zipf-1.1-100-stream-1000000.eps}}
          \label{power-law-z-1.1-100-stream-1000000}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
          \centering
          \resizebox{\linewidth}{!}{\includegraphics{eps/zipf-1.4-100-stream-1000000.eps}}
          \label{power-law-z-1.4-100-stream-1000000}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
          \centering
          \resizebox{\linewidth}{!}{\includegraphics{eps/zipf-1.7-100-stream-1000000.eps}}
          \label{power-law-z-1.7-100-stream-1000000}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
          \centering
          \resizebox{\linewidth}{!}{\includegraphics{eps/zipf-2.0-100-stream-1000000.eps}}
          \label{power-law-z-2.0-100-stream-1000000}
    \end{subfigure}
 
    \caption{Power-law distribution with $z = \{1.1, 1.4, 1.7, 2.0\}$ and data stream size $10^6$}
    \label{powerlaw}
\end{figure}

\section{Implementations}
\paragraph{Baseline}
Baseline algorithm is simple to implement. The algorithm holds counters $C$.
The $i^{th}$ item $x$ in data stream with $N$ items is called entry $<x, f>$. 
If $x$ is not in $C$ , set $C_n$ to $<x, 1>$. Otherwise, increment $C_x$ to $<x, f+1>$.
When user requests with support $s$, return the entries with $f$ greater than $f\cdot{}N$.
\paragraph{StickySampling \& LossyCounting \& SpaceSaving}
These three algorithms are implemented following the respective papers.

The theoretical performance of them should be what Table~\ref{theoretical_performance} shows.

\subsection{Theoretical Performance \& Justification}
\begin{table}[h!]
     \centering
      \begin{tabular}{||c | c | c| c| c||} 
      \hline
      & Baseline & StickySampling & LossyCounting & SpaceSaving \\ [0.5ex] 
      \hline\hline
      Update Time & $O(1)$ &  $O(\frac{20}{s}(log(\frac{100}{s}))$ & $O(\frac{10}{s}log(\frac{sN}{10}))$ & $O(log(s^{-1}))$ \\
      \hline
      Memory & $O(n)$ & $O(\frac{20}{s}(log(\frac{100}{s}))$ & $O(\frac{10}{s}log(\frac{sN}{10}))$& $O(s^{-1})$ \\ 
      \hline
      Accuracy & 100\% &545 & 778 & 7507 \\
      \hline
      \end{tabular}
     \caption{Theoretical performance of Baseline, StickySampling, LossyCounting and SpaceSaving;
      $s$ is support, $N$ is the current lenth of the stream and
      $n$ is the number of distinct items in stream.}
      \label{theoretical_performance}
\end{table}

The accuracy is defined to be $(TP + TN) / (TP + TN + FP + FN)$ 
where $TP$ is true positive, $TN$ is true negative, $FP$ is false negative and $FN$ is false negative.
\paragraph{Baseline}
The update time of Baseline is $O(1)$ because it just increament the corresponding $f$ with no other operation when updates.
Its memory cost is $O(n)$ since it stores every distinct items. And accuracy is 100\% obviously.
\paragraph{StickySampling}
In a power-law distribution data stream, the probability of occurrences drop rapidly at the begaining 
of the increasing order. In this kind of distribution, StickySampling algorithm works. 
This is because items with high probabilities tendd to appear earlier when the chance ($1/t$) to be selected is higher ($t$ increases thus $1/t$ drops).
After be selected, they also appears more. Thus, they accumulate higher frequencies to against frequency diminising at the timepoint of rate changing.
But items with lower probabilities have lower chance to be selected. 
Even they are selected, they have higher chance to be evicted at the diminising moment.
As the algorithm processing, items with higher probabilities are finally kept.

The memory cost of StickySampling is $O(\frac{2}{\epsilon}log(s^{-1}\delta^{-1})$ ? 
($\epsilon{}$ is chosen to be $s/10$ and $\delta{}$ is chosen to be 0.01).
Its update time is also $O(\frac{2}{\epsilon}log(s^{-1}\delta^{-1})$ because the counters are iterated when the rate $r$ changes.
\paragraph{LossyCounting}
The memory cost of StickySampling is $O(\frac{1}{\epsilon}log(\epsilon{}N))$ 
% because the chance of removing counter decreases as items coming when the items distribution is power-law, i.e., 
% new items have decresing chances to remove a counter at boundaries.
Its update time is then $O(\frac{1}{\epsilon}log(\epsilon{}N))$ because it iterates all counters at boundaries.
\paragraph{SpaceSaving}
SpaceSaving has a fixed number of counters which is $m = 1/s$, so its memory cost is $O(1/s)$. 
And the update time is $O(log(1/s))$ because the QuickSort is used when updates.

\section{Results \& Analysis}

\subsection{Memory \& Runtime \& Support}
Support $s$ from $10^{-5}$ to $10^{-2}$ were tested for the three algorithms and also Baseline,
see Figure~\ref{RuntimeSupport}.
Figure~\ref{MemoryRuntimeSupport} shows memory vs support. 
The maximum number of tracked items is used to present memory of the algorithms.
Figure~\ref{MaxTrackedSupport} shows runtime vs support.
Finally, Figure~\ref{MaxTrackedRuntime} shows memory vs runtime 
where the data is from the tests Figure~\ref{MaxTrackedSupport} and \ref{RuntimeSupport}.

\begin{figure}[!t]
      \centering
      \begin{subfigure}[b]{0.5\textwidth}
          \centering
           \resizebox{\linewidth}{!}{\includegraphics{eps/MaxTracked-Support-zipf-2.0-10000-delta-0.01-stream-100000.eps}}
           \caption{Maximum Number of Tracked Items vs Support}
           \label{MaxTrackedSupport}
     \end{subfigure}

     \begin{subfigure}[b]{0.5\textwidth}
            \centering
           \resizebox{\linewidth}{!}{\includegraphics{eps/Runtime-Support-zipf-2.0-10000-delta-0.01-stream-100000.eps}}
            \caption{Runtime vs Support}
           \label{RuntimeSupport}
     \end{subfigure}
     
     \begin{subfigure}[b]{0.5\textwidth}
            \centering
            \resizebox{\linewidth}{!}{\includegraphics{eps/MaxTracked-Runtime-zipf-2.0-10000-delta-0.01-stream-100000.eps}}
            \caption{Maximum Number of Tracked Items vs Runtime}
            \label{MaxTrackedRuntime}
      \end{subfigure}
     \caption{Memory \& Runtime \& Support; $z=2.0$, $10^{4}$ distinct items and $10^{5}$ items in stream.}  
      \label{MemoryRuntimeSupport}
 \end{figure}

 Figure~\ref{MaxTrackedSupport} indicates that they all have fixed memory .
 Because as the items coming, they store most of the items that have high probabilities.
But for SpaceSaving, the fixed memory is $1/s$, so it drops when $s$ increases. 
Thus, it cannot store the most frequent items at some point. 

Figure~\ref{RuntimeSupport} indicates that SpaceSaving has a increaing trend of runtime when
support increases. This is because it has more counters to sort when $s$ is greater.
However, runtime of StickySampling and LossyCounting do not change much.
This can be explained by the update time row of Table~\ref{theoretical_performance}.
As Table~\ref{theoretical_performance} shows, the increament of $s$ does not 
affect runtime of StickySampling much. And for LossyCounting, stream size $N$
affects much more than $s$. In addition, runtime of StickySampling and SpaceSaving are not affected by $N$, 
LossyCounting has higher runtime than them.

\subsection{Average Relative Error vs Support}
Figure~\ref{AverageRelativeErrorSupport} shows the average relative error of StickySampling, LossyCounting and SpaceSaving.

 \begin{figure}
      \centering
     \begin{subfigure}[b]{0.8\textwidth}
      \centering
      \resizebox{\linewidth}{!}{\includegraphics{eps/AverageRelativeError-Support-zipf-2.0-100-delta-0.01-stream-100000.eps}} 
      \end{subfigure}
      \caption{Average Relative Error vs Support}  
      \label{AverageRelativeErrorSupport}
 \end{figure}

\bibliographystyle{IEEEtran}
\bibliography{main}
\end{document}
